{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, dim, vocab_size):\n",
    "        super(Embeddings,self).__init__() # == super().__init__() \n",
    "        self.lut = nn.Embedding(vocab_size,dim)\n",
    "        self.d_model = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_size = (1,6,6)\n",
    "subseq_mask = np.triu(np.ones(attention_size),k=1)\n",
    "subseq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attention_size = (1,size,size)\n",
    "    subseq_mask = np.triu(np.ones(attention_size),k=1)\n",
    "    return torch.from_numpy(1-subseq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 0., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 1.]]], dtype=torch.float64),\n",
       " torch.Size([1, 6, 6]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trid = subsequent_mask(6)\n",
    "trid,trid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10,3)\n",
    "type(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6451, -0.1286, -0.6585],\n",
       "        [-1.1187, -0.1429,  0.0454],\n",
       "        [ 0.7862, -0.8243, -2.0834],\n",
       "        [-0.3729,  0.5265, -0.6919],\n",
       "        [-0.1460,  0.6052, -1.1296],\n",
       "        [-0.0972,  0.1188,  0.3157],\n",
       "        [ 0.0950, -0.7536, -0.9331],\n",
       "        [-0.6951, -0.9528, -0.5592],\n",
       "        [-1.2246, -0.5633,  1.7734],\n",
       "        [ 0.7964,  1.1891,  0.5069]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.LongTensor([[1,2,3,4],[0,6,7,8]])\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1187, -0.1429,  0.0454],\n",
       "         [ 0.7862, -0.8243, -2.0834],\n",
       "         [-0.3729,  0.5265, -0.6919],\n",
       "         [-0.1460,  0.6052, -1.1296]],\n",
       "\n",
       "        [[ 0.6451, -0.1286, -0.6585],\n",
       "         [ 0.0950, -0.7536, -0.9331],\n",
       "         [-0.6951, -0.9528, -0.5592],\n",
       "         [-1.2246, -0.5633,  1.7734]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [0, 6, 7, 8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x),type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))\n",
    "d_model =512\n",
    "vocab_size = 10000\n",
    "embs = Embeddings(d_model,vocab_size= vocab_size)\n",
    "inputs_emb = embs(x)\n",
    "query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_emb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, torch.Size([2, 4, 512]), 512)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_emb.shape[-1],inputs_emb.size(),inputs_emb.size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask = None, dropout = None):\n",
    "    d_k = query.size()[-1]\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1))/math.sqrt(d_k) #key last dim exchange with last 2nd dim\n",
    "    print(scores.size())\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "    attn = F.softmax(scores, dim = -1)\n",
    "    print(attn.size())\n",
    "    if dropout is not None:\n",
    "        attn = dropout(attn)\n",
    "    return torch.matmul(attn, value), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n",
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "values, attn = attention(query,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def clones(module, n = 1):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head, embedding_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        assert embedding_dim % head == 0\n",
    "        self.d_k =  embedding_dim// head\n",
    "        self.head = head\n",
    "        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        # if mask\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(0) # expand the dim of mask? represent nth head in multihead\n",
    "        batch_size = query.size()[0]\n",
    "        query, key, value = [model(x).view(batch_size, -1, self.head,self.d_k).transpose(1,2) for model, x in zip(self.linears, (query, key, value))] # transpose -1 means length of sentence, finally, last two dims are length of sentence and word emb dim\n",
    "        x, self.attn = attention(query, key, value, mask = mask, dropout = self.dropout)\n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.d_k*self.head)\n",
    "        return self.linears[-1](x)            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 8\n",
    "embedding_dim = 512\n",
    "dropout = 0.2\n",
    "#input\n",
    "query = key = value = inputs_emb\n",
    "mask = Variable(torch.zeros(8,4,4)) # number of head, matrix dim\n",
    "mask1 = mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
    "batch_size = query.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 4, 512]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = linears[0](query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = aa.view(batch_size, -1, head,embedding_dim//head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1, key1, value1 = [model(x).view(batch_size, -1, head,embedding_dim//head).transpose(1,2) for model, x in zip(linears, (query, key, value))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 512]), torch.Size([2, 8, 4, 64]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape,query1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask = None, dropout = None):\n",
    "    d_k = query.size()[-1]\n",
    "    #print(query.size())\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1))/math.sqrt(d_k) #key last dim exchange with last 2nd dim\n",
    "    #print(scores.size())\n",
    "    if mask is not None:\n",
    "        #print(mask.size())\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "        #print(scores)\n",
    "    attn = F.softmax(scores, dim = -1)\n",
    "    #print(attn.size())\n",
    "    if dropout is not None:\n",
    "        attn = dropout(attn)\n",
    "    return torch.matmul(attn, value), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1.shape == key1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, attn = attention(query1, key1, value1, mask = mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(linears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 4])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(head, embedding_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_result = mha(query,key,value,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.8329,  6.1361,  2.9585,  ...,  1.2148,  4.6935,  3.1532],\n",
       "         [-6.2393,  5.5863,  8.1964,  ...,  2.0062,  0.5491, -0.3885],\n",
       "         [-7.3728,  5.7970,  3.0365,  ...,  1.6352,  7.0970,  2.4296],\n",
       "         [-5.3376,  5.8210,  5.1375,  ...,  0.0529,  5.9840,  5.0678]],\n",
       "\n",
       "        [[-4.0066,  0.9095,  2.0274,  ...,  2.2734, -3.3347,  0.4291],\n",
       "         [-5.4267, -0.2141, -1.4938,  ...,  1.0425, -1.9053,  0.6388],\n",
       "         [ 0.2700,  3.5488,  2.8186,  ...,  0.5663, -7.8385,  3.2293],\n",
       "         [-3.1080,  1.5369,  1.9338,  ...,  3.1487, -1.8609,  1.8219]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(d_model, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, attn_output):\n",
    "        return self.w2(self.dropout(F.relu(self.w1(attn_output))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "d_ff = 128\n",
    "x = mha_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = PositionWiseFeedForward(d_model,d_ff)\n",
    "ffn_result = ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = nn.Parameter(torch.ones(1))\n",
    "ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_k, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.a1 = nn.Parameter(torch.ones(d_k))\n",
    "        self.b1 = nn.Parameter(torch.zeros(d_k))\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        x_mean = x.mean(-1,keepdim=True) # word embedding mean\n",
    "        x_std = x.std(-1,keepdim=True)\n",
    "        return self.a1*(x-x_mean)/(x_std+self.eps) +self.b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = d_model = 512\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0625,  2.7964, -0.2708,  ...,  2.0266, -0.4185, -1.2691],\n",
      "         [ 0.1676,  1.1957, -1.0197,  ...,  2.2087, -2.2657, -0.3799],\n",
      "         [-0.0221,  2.9585, -0.3438,  ...,  2.5006, -1.4301, -1.5331],\n",
      "         [ 1.7183,  1.5818, -0.3684,  ...,  2.1696, -1.7292, -0.9320]],\n",
      "\n",
      "        [[ 0.4740,  2.0729,  0.1291,  ...,  0.5363, -1.0441,  0.7311],\n",
      "         [ 0.2172,  2.1022,  0.7545,  ...,  0.9775, -0.4765,  1.1576],\n",
      "         [-0.2690,  2.3228,  0.6269,  ...,  0.3169, -1.1312,  1.7287],\n",
      "         [ 0.4810,  0.2195,  1.0199,  ...,  0.0603, -0.7871,  2.0044]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(d_model,eps)\n",
    "normalized_r = ln(ffn_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubLayerConnection(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.d_model = d_model\n",
    "        self.norm = LayerNorm(d_model)\n",
    "    def forward(self,x,sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))\n",
    "d_model =512\n",
    "vocab_size = 10000\n",
    "embs = Embeddings(d_model,vocab_size= vocab_size)\n",
    "inputs_emb = embs(x)\n",
    "query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 512\n",
    "head = 8\n",
    "dropout = 0.2\n",
    "mask = Variable(torch.zeros(8,4,4))\n",
    "self_attn = MultiHeadAttention(head, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublayer = lambda x:self_attn(x,x,x, mask)\n",
    "sc = SubLayerConnection(d_model, dropout)\n",
    "sc_result = sc(sublayer, inputs_emb)\n",
    "sc_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, selfattn, feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.attn = selfattn\n",
    "        self.ff = feedforward\n",
    "        self.sublayer = clones(SubLayerConnection(d_model, dropout),2)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # first sublayer 1 that contains multihead attn\n",
    "        # second sublayer 2 that contains ffn\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        x = self.sublayer[0](x, lambda x: self.attn(x,x,x,mask))\n",
    "        return self.sublayer[1](x, self.ff)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0,max_len).unsqueeze(1) # shape maxlen x 1\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2) * -(math.log(10000.0)/d_model))\n",
    "        pe[:,0::2] = torch.sin(position * div_term)\n",
    "        pe[:,1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self,x):\n",
    "        x += Variable(self.pe[:,:x.size(1)], requires_grad= False)\n",
    "        return self.dropout(x)\n",
    "# x = torch.tensor([1,2,3,4])\n",
    "# print(x.shape)\n",
    "# y = torch.unsqueeze(x,0)\n",
    "# print(y.shape)\n",
    "# z =  torch.unsqueeze(x,1)\n",
    "# print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))\n",
    "size = d_model = 512\n",
    "dropout = 0.1\n",
    "max_len = 60\n",
    "vocab_size = 10000\n",
    "embr = Embeddings(d_model,vocab_size= vocab_size)\n",
    "x = embr(x)\n",
    "x.shape\n",
    "\n",
    "#query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model, dropout=dropout, max_len=max_len)\n",
    "pe_result = pe(x)\n",
    "pe_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
       "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
       "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
       "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
       "\n",
       "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
       "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
       "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
       "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 512\n",
    "num_head = 8\n",
    "d_ff = 128\n",
    "query = key = value = inputs_emb = x\n",
    "dropout = 0.2\n",
    "self_attn = MultiHeadAttention(num_head,d_model)\n",
    "ff = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "mask = Variable(torch.zeros(8,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
      "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
      "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
      "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
      "\n",
      "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
      "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
      "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
      "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
      "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
      "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
      "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
      "\n",
      "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
      "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
      "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
      "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.8977, -11.8532,  -5.5989,  ..., -30.5247,  66.4291, -38.4195],\n",
      "         [ 29.6795,   0.3000, -46.3571,  ..., -17.4071,  31.7368,   7.1843],\n",
      "         [ 24.2859, -14.2270, -24.0474,  ..., -46.4053,  51.9067, -46.5041],\n",
      "         [ 39.2754, -21.2358, -26.1711,  ...,   1.3997,  -7.3988,  28.6062]],\n",
      "\n",
      "        [[-29.2911, -29.1776,  48.0573,  ...,   4.4771,  19.0327, -39.0777],\n",
      "         [  0.1069,  -0.3752,  -6.5175,  ..., -49.2793,   5.7932, -19.8507],\n",
      "         [-24.7635,  24.9703, -13.7633,  ...,  20.5051,  50.5663,  -8.2284],\n",
      "         [ -8.9811,  -5.0801,  23.5623,  ...,  -2.6834, -16.5013,  17.4808]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.7559, -11.9275,  -5.5290,  ..., -30.6108,  66.5888, -38.4028],\n",
      "         [ 29.2733,   0.7856, -46.3974,  ..., -17.1995,  31.8864,   7.6977],\n",
      "         [ 24.3709, -13.9674, -23.7230,  ..., -46.1527,  52.2649, -46.6996],\n",
      "         [ 38.9025, -21.1810, -26.0373,  ...,   1.3997,  -7.2437,  28.9588]],\n",
      "\n",
      "        [[-29.4358, -29.3428,  47.8681,  ...,   4.8809,  19.6758, -39.4204],\n",
      "         [  0.2951,   0.1317,  -6.6274,  ..., -48.5752,   6.0995, -19.7772],\n",
      "         [-24.8413,  25.3626, -13.5335,  ...,  20.5885,  50.9651,  -8.4840],\n",
      "         [ -8.5228,  -5.0801,  23.9107,  ...,  -2.5703, -16.6101,  17.2418]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "enc_layer = EncoderLayer(d_model, self_attn, ff, dropout)\n",
    "enc_res = enc_layer(pe_result, mask)\n",
    "print(enc_res)\n",
    "print(enc_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
