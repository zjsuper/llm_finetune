{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, dim, vocab_size):\n",
    "        super(Embeddings,self).__init__() # == super().__init__() \n",
    "        self.lut = nn.Embedding(vocab_size,dim)\n",
    "        self.d_model = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_size = (1,6,6)\n",
    "subseq_mask = np.triu(np.ones(attention_size),k=1)\n",
    "subseq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attention_size = (1,size,size)\n",
    "    subseq_mask = np.triu(np.ones(attention_size),k=1)\n",
    "    return torch.from_numpy(1-subseq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 0., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 1.]]], dtype=torch.float64),\n",
       " torch.Size([1, 6, 6]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trid = subsequent_mask(6)\n",
    "trid,trid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10,3)\n",
    "type(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6451, -0.1286, -0.6585],\n",
       "        [-1.1187, -0.1429,  0.0454],\n",
       "        [ 0.7862, -0.8243, -2.0834],\n",
       "        [-0.3729,  0.5265, -0.6919],\n",
       "        [-0.1460,  0.6052, -1.1296],\n",
       "        [-0.0972,  0.1188,  0.3157],\n",
       "        [ 0.0950, -0.7536, -0.9331],\n",
       "        [-0.6951, -0.9528, -0.5592],\n",
       "        [-1.2246, -0.5633,  1.7734],\n",
       "        [ 0.7964,  1.1891,  0.5069]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.LongTensor([[1,2,3,4],[0,6,7,8]])\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1187, -0.1429,  0.0454],\n",
       "         [ 0.7862, -0.8243, -2.0834],\n",
       "         [-0.3729,  0.5265, -0.6919],\n",
       "         [-0.1460,  0.6052, -1.1296]],\n",
       "\n",
       "        [[ 0.6451, -0.1286, -0.6585],\n",
       "         [ 0.0950, -0.7536, -0.9331],\n",
       "         [-0.6951, -0.9528, -0.5592],\n",
       "         [-1.2246, -0.5633,  1.7734]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [0, 6, 7, 8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x),type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))\n",
    "d_model =512\n",
    "vocab_size = 10000\n",
    "embs = Embeddings(d_model,vocab_size= vocab_size)\n",
    "inputs_emb = embs(x)\n",
    "query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_emb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, torch.Size([2, 4, 512]), 512)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_emb.shape[-1],inputs_emb.size(),inputs_emb.size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask = None, dropout = None):\n",
    "    d_k = query.size()[-1]\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1))/math.sqrt(d_k) #key last dim exchange with last 2nd dim\n",
    "    print(scores.size())\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "    attn = F.softmax(scores, dim = -1)\n",
    "    print(attn.size())\n",
    "    if dropout is not None:\n",
    "        attn = dropout(attn)\n",
    "    return torch.matmul(attn, value), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n",
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "values, attn = attention(query,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def clones(module, n = 1):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head, embedding_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        assert embedding_dim % head == 0\n",
    "        self.d_k =  embedding_dim// head\n",
    "        self.head = head\n",
    "        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        # if mask\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(0) # expand the dim of mask? represent nth head in multihead\n",
    "        batch_size = query.size()[0]\n",
    "        query, key, value = [model(x).view(batch_size, -1, self.head,self.d_k).transpose(1,2) for model, x in zip(self.linears, (query, key, value))] # transpose -1 means length of sentence, finally, last two dims are length of sentence and word emb dim\n",
    "        x, self.attn = attention(query, key, value, mask = mask, dropout = self.dropout)\n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.d_k*self.head)\n",
    "        return self.linears[-1](x)            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = 8\n",
    "embedding_dim = 512\n",
    "dropout = 0.2\n",
    "#input\n",
    "query = key = value = inputs_emb\n",
    "mask = Variable(torch.zeros(8,4,4)) # number of head, matrix dim\n",
    "mask1 = mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "linears = clones(nn.Linear(embedding_dim, embedding_dim), 4)\n",
    "batch_size = query.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 4, 512]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = linears[0](query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = aa.view(batch_size, -1, head,embedding_dim//head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1, key1, value1 = [model(x).view(batch_size, -1, head,embedding_dim//head).transpose(1,2) for model, x in zip(linears, (query, key, value))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 4, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 512]), torch.Size([2, 8, 4, 64]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape,query1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask = None, dropout = None):\n",
    "    d_k = query.size()[-1]\n",
    "    #print(query.size())\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1))/math.sqrt(d_k) #key last dim exchange with last 2nd dim\n",
    "    #print(scores.size())\n",
    "    if mask is not None:\n",
    "        #print(mask.size())\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "        #print(scores)\n",
    "    attn = F.softmax(scores, dim = -1)\n",
    "    #print(attn.size())\n",
    "    if dropout is not None:\n",
    "        attn = dropout(attn)\n",
    "    return torch.matmul(attn, value), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1.shape == key1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, attn = attention(query1, key1, value1, mask = mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(linears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 4])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(head, embedding_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_result = mha(query,key,value,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.8329,  6.1361,  2.9585,  ...,  1.2148,  4.6935,  3.1532],\n",
       "         [-6.2393,  5.5863,  8.1964,  ...,  2.0062,  0.5491, -0.3885],\n",
       "         [-7.3728,  5.7970,  3.0365,  ...,  1.6352,  7.0970,  2.4296],\n",
       "         [-5.3376,  5.8210,  5.1375,  ...,  0.0529,  5.9840,  5.0678]],\n",
       "\n",
       "        [[-4.0066,  0.9095,  2.0274,  ...,  2.2734, -3.3347,  0.4291],\n",
       "         [-5.4267, -0.2141, -1.4938,  ...,  1.0425, -1.9053,  0.6388],\n",
       "         [ 0.2700,  3.5488,  2.8186,  ...,  0.5663, -7.8385,  3.2293],\n",
       "         [-3.1080,  1.5369,  1.9338,  ...,  3.1487, -1.8609,  1.8219]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(d_model, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, attn_output):\n",
    "        return self.w2(self.dropout(F.relu(self.w1(attn_output))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "d_ff = 128\n",
    "x = mha_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = PositionWiseFeedForward(d_model,d_ff)\n",
    "ffn_result = ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = nn.Parameter(torch.ones(1))\n",
    "ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_k, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.a1 = nn.Parameter(torch.ones(d_k))\n",
    "        self.b1 = nn.Parameter(torch.zeros(d_k))\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        x_mean = x.mean(-1,keepdim=True) # word embedding mean\n",
    "        x_std = x.std(-1,keepdim=True)\n",
    "        return self.a1*(x-x_mean)/(x_std+self.eps) +self.b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = d_model = 512\n",
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0625,  2.7964, -0.2708,  ...,  2.0266, -0.4185, -1.2691],\n",
      "         [ 0.1676,  1.1957, -1.0197,  ...,  2.2087, -2.2657, -0.3799],\n",
      "         [-0.0221,  2.9585, -0.3438,  ...,  2.5006, -1.4301, -1.5331],\n",
      "         [ 1.7183,  1.5818, -0.3684,  ...,  2.1696, -1.7292, -0.9320]],\n",
      "\n",
      "        [[ 0.4740,  2.0729,  0.1291,  ...,  0.5363, -1.0441,  0.7311],\n",
      "         [ 0.2172,  2.1022,  0.7545,  ...,  0.9775, -0.4765,  1.1576],\n",
      "         [-0.2690,  2.3228,  0.6269,  ...,  0.3169, -1.1312,  1.7287],\n",
      "         [ 0.4810,  0.2195,  1.0199,  ...,  0.0603, -0.7871,  2.0044]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(d_model,eps)\n",
    "normalized_r = ln(ffn_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubLayerConnection(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.d_model = d_model\n",
    "        self.norm = LayerNorm(d_model)\n",
    "    def forward(self,x,sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))\n",
    "d_model =512\n",
    "vocab_size = 10000\n",
    "embs = Embeddings(d_model,vocab_size= vocab_size)\n",
    "inputs_emb = embs(x)\n",
    "query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 512\n",
    "head = 8\n",
    "dropout = 0.2\n",
    "mask = Variable(torch.zeros(8,4,4))\n",
    "self_attn = MultiHeadAttention(head, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublayer = lambda x:self_attn(x,x,x, mask)\n",
    "sc = SubLayerConnection(d_model, dropout)\n",
    "sc_result = sc(sublayer, inputs_emb)\n",
    "sc_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, selfattn, feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.attn = selfattn\n",
    "        self.ff = feedforward\n",
    "        self.sublayer = clones(SubLayerConnection(d_model, dropout),2)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # first sublayer 1 that contains multihead attn\n",
    "        # second sublayer 2 that contains ffn\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        x = self.sublayer[0](x, lambda x: self.attn(x,x,x,mask))\n",
    "        return self.sublayer[1](x, self.ff)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0,max_len).unsqueeze(1) # shape maxlen x 1\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2) * -(math.log(10000.0)/d_model))\n",
    "        pe[:,0::2] = torch.sin(position * div_term)\n",
    "        pe[:,1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self,x):\n",
    "        x += Variable(self.pe[:,:x.size(1)], requires_grad= False)\n",
    "        return self.dropout(x)\n",
    "# x = torch.tensor([1,2,3,4])\n",
    "# print(x.shape)\n",
    "# y = torch.unsqueeze(x,0)\n",
    "# print(y.shape)\n",
    "# z =  torch.unsqueeze(x,1)\n",
    "# print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.LongTensor([[1,2,3,4],[0,6,7,8]]))\n",
    "size = d_model = 512\n",
    "dropout = 0.1\n",
    "max_len = 60\n",
    "vocab_size = 10000\n",
    "embr = Embeddings(d_model,vocab_size= vocab_size)\n",
    "x = embr(x)\n",
    "x.shape\n",
    "\n",
    "#query = key = value = inputs_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model, dropout=dropout, max_len=max_len)\n",
    "pe_result = pe(x)\n",
    "pe_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
       "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
       "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
       "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
       "\n",
       "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
       "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
       "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
       "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 512\n",
    "num_head = 8\n",
    "d_ff = 128\n",
    "query = key = value = inputs_emb = x\n",
    "dropout = 0.2\n",
    "self_attn = MultiHeadAttention(num_head,d_model)\n",
    "ff = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "mask = Variable(torch.zeros(8,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 512])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
      "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
      "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
      "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
      "\n",
      "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
      "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
      "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
      "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
      "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
      "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
      "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
      "\n",
      "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
      "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
      "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
      "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.8977, -11.8532,  -5.5989,  ..., -30.5247,  66.4291, -38.4195],\n",
      "         [ 29.6795,   0.3000, -46.3571,  ..., -17.4071,  31.7368,   7.1843],\n",
      "         [ 24.2859, -14.2270, -24.0474,  ..., -46.4053,  51.9067, -46.5041],\n",
      "         [ 39.2754, -21.2358, -26.1711,  ...,   1.3997,  -7.3988,  28.6062]],\n",
      "\n",
      "        [[-29.2911, -29.1776,  48.0573,  ...,   4.4771,  19.0327, -39.0777],\n",
      "         [  0.1069,  -0.3752,  -6.5175,  ..., -49.2793,   5.7932, -19.8507],\n",
      "         [-24.7635,  24.9703, -13.7633,  ...,  20.5051,  50.5663,  -8.2284],\n",
      "         [ -8.9811,  -5.0801,  23.5623,  ...,  -2.6834, -16.5013,  17.4808]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.7559, -11.9275,  -5.5290,  ..., -30.6108,  66.5888, -38.4028],\n",
      "         [ 29.2733,   0.7856, -46.3974,  ..., -17.1995,  31.8864,   7.6977],\n",
      "         [ 24.3709, -13.9674, -23.7230,  ..., -46.1527,  52.2649, -46.6996],\n",
      "         [ 38.9025, -21.1810, -26.0373,  ...,   1.3997,  -7.2437,  28.9588]],\n",
      "\n",
      "        [[-29.4358, -29.3428,  47.8681,  ...,   4.8809,  19.6758, -39.4204],\n",
      "         [  0.2951,   0.1317,  -6.6274,  ..., -48.5752,   6.0995, -19.7772],\n",
      "         [-24.8413,  25.3626, -13.5335,  ...,  20.5885,  50.9651,  -8.4840],\n",
      "         [ -8.5228,  -5.0801,  23.9107,  ...,  -2.5703, -16.6101,  17.2418]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "enc_layer = EncoderLayer(d_model, self_attn, ff, dropout)\n",
    "enc_res = enc_layer(pe_result, mask)\n",
    "print(enc_res)\n",
    "print(enc_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        # layer: encoding layer\n",
    "        # N : number of layers\n",
    "        super().__init__()\n",
    "        # use clones first to clone n encoding layer\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.d_model)\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 512\n",
    "num_head = 8\n",
    "d_ff = 128\n",
    "c = copy.deepcopy\n",
    "\n",
    "dropout = 0.2\n",
    "self_attn = MultiHeadAttention(num_head,d_model)\n",
    "ff = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "layer = EncoderLayer(d_model, c(self_attn),c(ff), dropout)\n",
    "N = 8\n",
    "mask = Variable(torch.zeros(8,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
      "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
      "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
      "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
      "\n",
      "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
      "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
      "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
      "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 25.1559, -12.0865,  -5.5447,  ..., -30.4957,  66.4291, -38.6705],\n",
      "         [ 29.9158,  -0.0000, -46.5394,  ..., -17.3306,  31.7749,   7.0996],\n",
      "         [ 24.5923, -14.4718, -24.1787,  ..., -46.4053,  51.8896, -46.5875],\n",
      "         [ 39.6145, -21.5813, -26.3686,  ...,   1.3935,  -7.3859,  28.4846]],\n",
      "\n",
      "        [[-29.2657, -28.9459,  48.3231,  ...,   4.6213,  18.8426, -38.9961],\n",
      "         [ -0.0000,  -0.0000,  -6.2620,  ..., -49.2851,   5.8389, -19.7380],\n",
      "         [-24.6691,  25.3550, -13.5024,  ...,  20.6753,  50.4802,  -8.0211],\n",
      "         [ -8.8985,  -4.7571,  23.8176,  ...,  -2.5692, -16.4691,  17.5743]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.5156e+01, -1.1442e+01, -5.8597e+00,  ..., -3.0505e+01,\n",
      "           6.6591e+01, -3.8998e+01],\n",
      "         [ 2.9595e+01,  5.5620e-01, -4.6829e+01,  ..., -1.7307e+01,\n",
      "           3.1861e+01,  6.6552e+00],\n",
      "         [ 2.4592e+01, -1.3715e+01, -2.4367e+01,  ..., -4.6366e+01,\n",
      "           5.1910e+01, -4.6978e+01],\n",
      "         [ 3.9034e+01, -2.0935e+01, -2.6687e+01,  ...,  1.4911e+00,\n",
      "          -7.2196e+00,  2.8239e+01]],\n",
      "\n",
      "        [[-2.9193e+01, -2.8722e+01,  4.8102e+01,  ...,  4.6213e+00,\n",
      "           1.8789e+01, -3.8790e+01],\n",
      "         [ 6.2425e-02,  1.8988e-01, -6.5232e+00,  ..., -4.9285e+01,\n",
      "           5.8389e+00, -1.9512e+01],\n",
      "         [-2.4715e+01,  2.5439e+01, -1.3576e+01,  ...,  2.0539e+01,\n",
      "           5.0751e+01, -7.8602e+00],\n",
      "         [-8.8985e+00, -4.4290e+00,  2.3499e+01,  ..., -2.5841e+00,\n",
      "          -1.6486e+01,  1.7687e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.5002e+01, -1.1629e+01, -5.9761e+00,  ..., -3.0620e+01,\n",
      "           6.7136e+01, -3.8998e+01],\n",
      "         [ 2.9137e+01,  6.3845e-01, -4.6935e+01,  ..., -1.7307e+01,\n",
      "           3.1861e+01,  7.5535e+00],\n",
      "         [ 2.4749e+01, -1.3943e+01, -2.4724e+01,  ..., -4.6656e+01,\n",
      "           5.1910e+01, -4.7709e+01],\n",
      "         [ 3.9034e+01, -2.1480e+01, -2.7238e+01,  ...,  1.4724e+00,\n",
      "          -6.8830e+00,  2.8403e+01]],\n",
      "\n",
      "        [[-2.9404e+01, -2.9074e+01,  4.8475e+01,  ...,  4.8169e+00,\n",
      "           1.8789e+01, -3.8790e+01],\n",
      "         [ 5.9597e-02,  2.8327e-01, -7.0857e+00,  ..., -4.9285e+01,\n",
      "           6.4289e+00, -1.9512e+01],\n",
      "         [-2.4715e+01,  2.5229e+01, -1.3562e+01,  ...,  2.0434e+01,\n",
      "           5.0751e+01, -7.8835e+00],\n",
      "         [-8.8476e+00, -4.3182e+00,  2.2918e+01,  ..., -3.2529e+00,\n",
      "          -1.6168e+01,  1.7687e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.5002e+01, -1.1629e+01, -5.9761e+00,  ..., -3.0620e+01,\n",
      "           6.7136e+01, -3.8998e+01],\n",
      "         [ 2.9137e+01,  6.3845e-01, -4.6935e+01,  ..., -1.7307e+01,\n",
      "           3.1861e+01,  7.5535e+00],\n",
      "         [ 2.4749e+01, -1.3943e+01, -2.4724e+01,  ..., -4.6656e+01,\n",
      "           5.1910e+01, -4.7709e+01],\n",
      "         [ 3.9034e+01, -2.1480e+01, -2.7238e+01,  ...,  1.4724e+00,\n",
      "          -6.8830e+00,  2.8403e+01]],\n",
      "\n",
      "        [[-2.9404e+01, -2.9074e+01,  4.8475e+01,  ...,  4.8169e+00,\n",
      "           1.8789e+01, -3.8790e+01],\n",
      "         [ 5.9597e-02,  2.8327e-01, -7.0857e+00,  ..., -4.9285e+01,\n",
      "           6.4289e+00, -1.9512e+01],\n",
      "         [-2.4715e+01,  2.5229e+01, -1.3562e+01,  ...,  2.0434e+01,\n",
      "           5.0751e+01, -7.8835e+00],\n",
      "         [-8.8476e+00, -4.3182e+00,  2.2918e+01,  ..., -3.2529e+00,\n",
      "          -1.6168e+01,  1.7687e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.4563e+01, -1.0971e+01, -5.9761e+00,  ..., -3.0620e+01,\n",
      "           6.7319e+01, -3.9283e+01],\n",
      "         [ 2.8631e+01,  1.2948e+00, -4.7141e+01,  ..., -1.7345e+01,\n",
      "           3.2025e+01,  7.2520e+00],\n",
      "         [ 2.4263e+01, -1.3943e+01, -2.4867e+01,  ..., -4.6480e+01,\n",
      "           5.1910e+01, -4.7709e+01],\n",
      "         [ 3.8607e+01, -2.0816e+01, -2.7238e+01,  ...,  1.6349e+00,\n",
      "          -6.6818e+00,  2.8088e+01]],\n",
      "\n",
      "        [[-2.9413e+01, -2.8853e+01,  4.8150e+01,  ...,  4.7679e+00,\n",
      "           1.8873e+01, -3.8645e+01],\n",
      "         [ 1.2539e-02,  4.2043e-01, -7.3835e+00,  ..., -4.9352e+01,\n",
      "           6.5269e+00, -1.9379e+01],\n",
      "         [-2.4715e+01,  2.5229e+01, -1.3817e+01,  ...,  2.0330e+01,\n",
      "           5.0751e+01, -7.7550e+00],\n",
      "         [-8.8476e+00, -4.0281e+00,  2.2742e+01,  ..., -3.3166e+00,\n",
      "          -1.6013e+01,  1.7855e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.5348, -10.8402,  -6.3004,  ..., -30.8580,  67.8789, -39.2831],\n",
      "         [ 28.6306,   1.4884, -47.5230,  ..., -17.4078,  32.0249,   7.9438],\n",
      "         [ 24.3661, -13.9862, -24.9172,  ..., -46.7556,  52.2176, -47.7091],\n",
      "         [ 38.6705, -20.8163, -27.9358,  ...,   1.4736,  -6.6818,  28.0879]],\n",
      "\n",
      "        [[-29.4129, -28.8534,  48.1932,  ...,   4.8763,  18.8992, -38.8240],\n",
      "         [  0.1435,   0.1973,  -8.2103,  ..., -49.2474,   7.3037, -18.7394],\n",
      "         [-24.7635,  25.2328, -14.0681,  ...,  20.3296,  50.8861,  -7.7550],\n",
      "         [ -8.9930,  -3.9451,  22.5096,  ...,  -3.5052, -15.7519,  17.8987]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.5348, -10.8402,  -6.3004,  ..., -30.8580,  67.8789, -39.2831],\n",
      "         [ 28.6306,   1.4884, -47.5230,  ..., -17.4078,  32.0249,   7.9438],\n",
      "         [ 24.3661, -13.9862, -24.9172,  ..., -46.7556,  52.2176, -47.7091],\n",
      "         [ 38.6705, -20.8163, -27.9358,  ...,   1.4736,  -6.6818,  28.0879]],\n",
      "\n",
      "        [[-29.4129, -28.8534,  48.1932,  ...,   4.8763,  18.8992, -38.8240],\n",
      "         [  0.1435,   0.1973,  -8.2103,  ..., -49.2474,   7.3037, -18.7394],\n",
      "         [-24.7635,  25.2328, -14.0681,  ...,  20.3296,  50.8861,  -7.7550],\n",
      "         [ -8.9930,  -3.9451,  22.5096,  ...,  -3.5052, -15.7519,  17.8987]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.1976, -10.8402,  -6.3004,  ..., -30.8532,  67.9917, -39.7574],\n",
      "         [ 28.0398,   2.2145, -47.5230,  ..., -17.4078,  32.0249,   7.4932],\n",
      "         [ 24.0942, -13.1559, -25.0867,  ..., -46.8465,  52.2500, -47.7091],\n",
      "         [ 38.3006, -19.9993, -28.1288,  ...,   1.4736,  -6.6818,  27.7066]],\n",
      "\n",
      "        [[-29.4757, -28.8534,  48.0465,  ...,   4.8763,  18.8992, -38.7303],\n",
      "         [  0.1435,   0.1973,  -8.2103,  ..., -49.2377,   7.2377, -18.7572],\n",
      "         [-24.7635,  25.4416, -14.3223,  ...,  20.2683,  51.1104,  -7.5564],\n",
      "         [ -9.0491,  -3.7170,  22.2566,  ...,  -3.5873, -15.6106,  18.0323]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.1976, -10.6323,  -6.3516,  ..., -30.5264,  68.4675, -39.6857],\n",
      "         [ 28.0398,   2.4272, -47.5230,  ..., -17.3990,  32.9540,   8.4531],\n",
      "         [ 24.0627, -13.4370, -25.1830,  ..., -46.8465,  52.6093, -48.2834],\n",
      "         [ 38.3006, -19.9993, -28.8643,  ...,   1.4741,  -6.4795,  28.2370]],\n",
      "\n",
      "        [[-29.4857, -29.1094,  48.2073,  ...,   5.0970,  18.7486, -38.7303],\n",
      "         [  0.3122,   0.0923,  -8.7068,  ..., -48.9662,   7.9930, -18.3430],\n",
      "         [-24.4390,  25.0241, -14.4624,  ...,  20.1833,  51.2453,  -7.6649],\n",
      "         [ -9.1199,  -3.3517,  21.8351,  ...,  -3.5873, -15.3443,  17.9431]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 24.1976, -10.6323,  -6.3516,  ..., -30.5264,  68.4675, -39.6857],\n",
      "         [ 28.0398,   2.4272, -47.5230,  ..., -17.3990,  32.9540,   8.4531],\n",
      "         [ 24.0627, -13.4370, -25.1830,  ..., -46.8465,  52.6093, -48.2834],\n",
      "         [ 38.3006, -19.9993, -28.8643,  ...,   1.4741,  -6.4795,  28.2370]],\n",
      "\n",
      "        [[-29.4857, -29.1094,  48.2073,  ...,   5.0970,  18.7486, -38.7303],\n",
      "         [  0.3122,   0.0923,  -8.7068,  ..., -48.9662,   7.9930, -18.3430],\n",
      "         [-24.4390,  25.0241, -14.4624,  ...,  20.1833,  51.2453,  -7.6649],\n",
      "         [ -9.1199,  -3.3517,  21.8351,  ...,  -3.5873, -15.3443,  17.9431]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 23.6911,  -9.9889,  -6.6969,  ..., -30.4309,  68.4675, -40.0571],\n",
      "         [ 27.6321,   2.4272, -47.8537,  ..., -17.1708,  33.0153,   8.1047],\n",
      "         [ 23.6020, -13.4370, -25.1830,  ..., -46.7382,  52.6093, -48.6073],\n",
      "         [ 37.9876, -19.3994, -28.8643,  ...,   1.5032,  -6.3928,  27.8549]],\n",
      "\n",
      "        [[-29.4588, -29.1094,  47.9763,  ...,   5.1041,  18.9162, -38.7303],\n",
      "         [  0.0884,   0.3379,  -9.0657,  ..., -48.9662,   7.9930, -18.1139],\n",
      "         [-24.5443,  25.2492, -14.4624,  ...,  20.1547,  51.4338,  -7.6491],\n",
      "         [ -9.1320,  -3.1512,  21.8351,  ...,  -3.6605, -15.3443,  18.1579]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 23.6911,  -9.5869,  -6.5407,  ..., -30.3818,  69.0792, -39.9821],\n",
      "         [ 27.1793,   2.6491, -47.8431,  ..., -16.8696,  33.0153,   9.2434],\n",
      "         [ 23.5783, -13.4370, -25.3311,  ..., -47.1838,  53.1792, -49.0937],\n",
      "         [ 38.1199, -19.3994, -29.3307,  ...,   1.5032,  -6.1899,  28.1204]],\n",
      "\n",
      "        [[-29.4588, -29.0772,  48.1333,  ...,   5.1041,  18.9162, -38.7331],\n",
      "         [  0.2402,  -0.1555,  -9.5810,  ..., -48.7511,   8.8353, -18.1139],\n",
      "         [-24.6587,  25.1167, -14.3929,  ...,  19.8100,  51.5738,  -7.6083],\n",
      "         [ -9.2542,  -3.1512,  21.3852,  ...,  -3.6699, -15.3443,  18.4008]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 23.6911,  -9.5869,  -6.5407,  ..., -30.3818,  69.0792, -39.9821],\n",
      "         [ 27.1793,   2.6491, -47.8431,  ..., -16.8696,  33.0153,   9.2434],\n",
      "         [ 23.5783, -13.4370, -25.3311,  ..., -47.1838,  53.1792, -49.0937],\n",
      "         [ 38.1199, -19.3994, -29.3307,  ...,   1.5032,  -6.1899,  28.1204]],\n",
      "\n",
      "        [[-29.4588, -29.0772,  48.1333,  ...,   5.1041,  18.9162, -38.7331],\n",
      "         [  0.2402,  -0.1555,  -9.5810,  ..., -48.7511,   8.8353, -18.1139],\n",
      "         [-24.6587,  25.1167, -14.3929,  ...,  19.8100,  51.5738,  -7.6083],\n",
      "         [ -9.2542,  -3.1512,  21.3852,  ...,  -3.6699, -15.3443,  18.4008]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 23.1627,  -8.9635,  -6.9035,  ..., -30.2823,  69.2712, -40.2666],\n",
      "         [ 26.5817,   3.3269, -48.1084,  ..., -16.8696,  33.1663,   8.8715],\n",
      "         [ 23.5783, -13.4370, -25.4721,  ..., -47.1838,  53.2856, -49.5393],\n",
      "         [ 37.5996, -18.6790, -29.5113,  ...,   1.6048,  -6.0655,  28.1204]],\n",
      "\n",
      "        [[-29.4005, -28.7954,  48.1333,  ...,   5.0894,  19.0868, -38.5933],\n",
      "         [  0.1372,   0.0996,  -9.7668,  ..., -48.8336,   8.9812, -18.0089],\n",
      "         [-24.7627,  25.3093, -14.3929,  ...,  19.6402,  51.6055,  -7.6176],\n",
      "         [ -9.3509,  -2.8638,  21.1433,  ...,  -3.7101, -15.1938,  18.4385]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.3067e+01, -8.5669e+00, -6.9645e+00,  ..., -3.0243e+01,\n",
      "           6.9954e+01, -4.0281e+01],\n",
      "         [ 2.6140e+01,  3.6015e+00, -4.8497e+01,  ..., -1.6870e+01,\n",
      "           3.3166e+01,  9.5995e+00],\n",
      "         [ 2.3452e+01, -1.3364e+01, -2.5589e+01,  ..., -4.7184e+01,\n",
      "           5.3601e+01, -4.9691e+01],\n",
      "         [ 3.7758e+01, -1.8619e+01, -2.9511e+01,  ...,  1.4521e+00,\n",
      "          -6.1215e+00,  2.8489e+01]],\n",
      "\n",
      "        [[-2.9569e+01, -2.8829e+01,  4.8254e+01,  ...,  5.2664e+00,\n",
      "           1.9013e+01, -3.8657e+01],\n",
      "         [ 1.3717e-01,  3.4178e-02, -9.7668e+00,  ..., -4.8400e+01,\n",
      "           9.9470e+00, -1.7636e+01],\n",
      "         [-2.4853e+01,  2.5198e+01, -1.4411e+01,  ...,  1.9494e+01,\n",
      "           5.1818e+01, -7.7072e+00],\n",
      "         [-9.4378e+00, -2.5455e+00,  2.1020e+01,  ..., -3.7878e+00,\n",
      "          -1.4800e+01,  1.8638e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.3067e+01, -8.5669e+00, -6.9645e+00,  ..., -3.0243e+01,\n",
      "           6.9954e+01, -4.0281e+01],\n",
      "         [ 2.6140e+01,  3.6015e+00, -4.8497e+01,  ..., -1.6870e+01,\n",
      "           3.3166e+01,  9.5995e+00],\n",
      "         [ 2.3452e+01, -1.3364e+01, -2.5589e+01,  ..., -4.7184e+01,\n",
      "           5.3601e+01, -4.9691e+01],\n",
      "         [ 3.7758e+01, -1.8619e+01, -2.9511e+01,  ...,  1.4521e+00,\n",
      "          -6.1215e+00,  2.8489e+01]],\n",
      "\n",
      "        [[-2.9569e+01, -2.8829e+01,  4.8254e+01,  ...,  5.2664e+00,\n",
      "           1.9013e+01, -3.8657e+01],\n",
      "         [ 1.3717e-01,  3.4178e-02, -9.7668e+00,  ..., -4.8400e+01,\n",
      "           9.9470e+00, -1.7636e+01],\n",
      "         [-2.4853e+01,  2.5198e+01, -1.4411e+01,  ...,  1.9494e+01,\n",
      "           5.1818e+01, -7.7072e+00],\n",
      "         [-9.4378e+00, -2.5455e+00,  2.1020e+01,  ..., -3.7878e+00,\n",
      "          -1.4800e+01,  1.8638e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 22.5556,  -7.9201,  -7.2376,  ..., -30.1488,  70.1407, -40.2811],\n",
      "         [ 25.6843,   4.2459, -48.7365,  ..., -16.8391,  33.2201,   9.2573],\n",
      "         [ 22.9569, -13.3636, -25.7890,  ..., -47.1578,  53.6014, -50.1313],\n",
      "         [ 37.2505, -18.6191, -29.5698,  ...,   1.4521,  -5.9822,  28.4895]],\n",
      "\n",
      "        [[-29.5693, -28.8294,  48.0779,  ...,   5.2901,  19.0195, -38.7878],\n",
      "         [  0.2012,   0.2040,  -9.9526,  ..., -48.4015,   9.9470, -17.6364],\n",
      "         [-24.9195,  25.1981, -14.6924,  ...,  19.4375,  51.9582,  -7.5534],\n",
      "         [ -9.5744,  -2.5455,  20.8640,  ...,  -3.9208, -14.6347,  18.7496]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.2556e+01, -7.9201e+00, -7.0059e+00,  ..., -2.9902e+01,\n",
      "           7.0141e+01, -4.0535e+01],\n",
      "         [ 2.5009e+01,  4.3166e+00, -4.8871e+01,  ..., -1.6839e+01,\n",
      "           3.3220e+01,  1.0009e+01],\n",
      "         [ 2.2865e+01, -1.3354e+01, -2.5825e+01,  ..., -4.7593e+01,\n",
      "           5.4012e+01, -5.0637e+01],\n",
      "         [ 3.7461e+01, -1.8753e+01, -3.0424e+01,  ...,  1.3703e+00,\n",
      "          -5.8233e+00,  2.9143e+01]],\n",
      "\n",
      "        [[-2.9647e+01, -2.8819e+01,  4.8078e+01,  ...,  5.7123e+00,\n",
      "           1.8752e+01, -3.8650e+01],\n",
      "         [ 5.3745e-02, -7.7860e-02, -1.0468e+01,  ..., -4.8218e+01,\n",
      "           1.0227e+01, -1.7392e+01],\n",
      "         [-2.4950e+01,  2.5317e+01, -1.4938e+01,  ...,  1.9438e+01,\n",
      "           5.1958e+01, -7.5175e+00],\n",
      "         [-9.8068e+00, -2.1231e+00,  2.0357e+01,  ..., -3.9208e+00,\n",
      "          -1.4523e+01,  1.8856e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.2556e+01, -7.9201e+00, -7.0059e+00,  ..., -2.9902e+01,\n",
      "           7.0141e+01, -4.0535e+01],\n",
      "         [ 2.5009e+01,  4.3166e+00, -4.8871e+01,  ..., -1.6839e+01,\n",
      "           3.3220e+01,  1.0009e+01],\n",
      "         [ 2.2865e+01, -1.3354e+01, -2.5825e+01,  ..., -4.7593e+01,\n",
      "           5.4012e+01, -5.0637e+01],\n",
      "         [ 3.7461e+01, -1.8753e+01, -3.0424e+01,  ...,  1.3703e+00,\n",
      "          -5.8233e+00,  2.9143e+01]],\n",
      "\n",
      "        [[-2.9647e+01, -2.8819e+01,  4.8078e+01,  ...,  5.7123e+00,\n",
      "           1.8752e+01, -3.8650e+01],\n",
      "         [ 5.3745e-02, -7.7860e-02, -1.0468e+01,  ..., -4.8218e+01,\n",
      "           1.0227e+01, -1.7392e+01],\n",
      "         [-2.4950e+01,  2.5317e+01, -1.4938e+01,  ...,  1.9438e+01,\n",
      "           5.1958e+01, -7.5175e+00],\n",
      "         [-9.8068e+00, -2.1231e+00,  2.0357e+01,  ..., -3.9208e+00,\n",
      "          -1.4523e+01,  1.8856e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.2123e+01, -7.3564e+00, -7.0059e+00,  ..., -2.9803e+01,\n",
      "           7.0141e+01, -4.0859e+01],\n",
      "         [ 2.4632e+01,  5.0640e+00, -4.9138e+01,  ..., -1.6791e+01,\n",
      "           3.3437e+01,  1.0009e+01],\n",
      "         [ 2.2279e+01, -1.2620e+01, -2.6092e+01,  ..., -4.7594e+01,\n",
      "           5.4174e+01, -5.0946e+01],\n",
      "         [ 3.7027e+01, -1.8146e+01, -3.0538e+01,  ...,  1.3904e+00,\n",
      "          -5.7469e+00,  2.8820e+01]],\n",
      "\n",
      "        [[-2.9733e+01, -2.8640e+01,  4.7897e+01,  ...,  5.7123e+00,\n",
      "           1.8886e+01, -3.8461e+01],\n",
      "         [ 6.0806e-02,  3.9357e-02, -1.0657e+01,  ..., -4.8223e+01,\n",
      "           1.0408e+01, -1.7265e+01],\n",
      "         [-2.5042e+01,  2.5591e+01, -1.5152e+01,  ...,  1.9438e+01,\n",
      "           5.2053e+01, -7.5175e+00],\n",
      "         [-9.7932e+00, -1.8794e+00,  2.0067e+01,  ..., -4.0029e+00,\n",
      "          -1.4509e+01,  1.8856e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.2235e+01, -6.9113e+00, -6.8790e+00,  ..., -2.9638e+01,\n",
      "           7.0141e+01, -4.0817e+01],\n",
      "         [ 2.4115e+01,  5.2638e+00, -4.9266e+01,  ..., -1.6567e+01,\n",
      "           3.4235e+01,  1.0009e+01],\n",
      "         [ 2.2428e+01, -1.2620e+01, -2.6168e+01,  ..., -4.7903e+01,\n",
      "           5.4782e+01, -5.0946e+01],\n",
      "         [ 3.7027e+01, -1.8365e+01, -3.0950e+01,  ...,  1.1756e+00,\n",
      "          -5.5840e+00,  2.8934e+01]],\n",
      "\n",
      "        [[-2.9721e+01, -2.8729e+01,  4.8241e+01,  ...,  5.7123e+00,\n",
      "           1.8869e+01, -3.8640e+01],\n",
      "         [ 1.7825e-01,  3.9357e-02, -1.1063e+01,  ..., -4.7668e+01,\n",
      "           1.1062e+01, -1.6964e+01],\n",
      "         [-2.5065e+01,  2.5591e+01, -1.5399e+01,  ...,  1.9129e+01,\n",
      "           5.2053e+01, -7.6086e+00],\n",
      "         [-1.0004e+01, -1.8794e+00,  1.9764e+01,  ..., -4.3446e+00,\n",
      "          -1.4509e+01,  1.9147e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.2235e+01, -6.9113e+00, -6.8790e+00,  ..., -2.9638e+01,\n",
      "           7.0141e+01, -4.0817e+01],\n",
      "         [ 2.4115e+01,  5.2638e+00, -4.9266e+01,  ..., -1.6567e+01,\n",
      "           3.4235e+01,  1.0009e+01],\n",
      "         [ 2.2428e+01, -1.2620e+01, -2.6168e+01,  ..., -4.7903e+01,\n",
      "           5.4782e+01, -5.0946e+01],\n",
      "         [ 3.7027e+01, -1.8365e+01, -3.0950e+01,  ...,  1.1756e+00,\n",
      "          -5.5840e+00,  2.8934e+01]],\n",
      "\n",
      "        [[-2.9721e+01, -2.8729e+01,  4.8241e+01,  ...,  5.7123e+00,\n",
      "           1.8869e+01, -3.8640e+01],\n",
      "         [ 1.7825e-01,  3.9357e-02, -1.1063e+01,  ..., -4.7668e+01,\n",
      "           1.1062e+01, -1.6964e+01],\n",
      "         [-2.5065e+01,  2.5591e+01, -1.5399e+01,  ...,  1.9129e+01,\n",
      "           5.2053e+01, -7.6086e+00],\n",
      "         [-1.0004e+01, -1.8794e+00,  1.9764e+01,  ..., -4.3446e+00,\n",
      "          -1.4509e+01,  1.9147e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.1818e+01, -6.1729e+00, -7.0317e+00,  ..., -2.9638e+01,\n",
      "           7.0256e+01, -4.1119e+01],\n",
      "         [ 2.3664e+01,  5.9207e+00, -4.9644e+01,  ..., -1.6567e+01,\n",
      "           3.4363e+01,  9.6852e+00],\n",
      "         [ 2.2000e+01, -1.2039e+01, -2.6168e+01,  ..., -4.7871e+01,\n",
      "           5.4953e+01, -5.1338e+01],\n",
      "         [ 3.6507e+01, -1.7645e+01, -3.1250e+01,  ...,  1.2814e+00,\n",
      "          -5.4304e+00,  2.8609e+01]],\n",
      "\n",
      "        [[-2.9721e+01, -2.8405e+01,  4.8035e+01,  ...,  5.7123e+00,\n",
      "           1.8940e+01, -3.8640e+01],\n",
      "         [ 2.5045e-01,  3.9357e-02, -1.1410e+01,  ..., -4.7696e+01,\n",
      "           1.1062e+01, -1.6813e+01],\n",
      "         [-2.5247e+01,  2.5591e+01, -1.5676e+01,  ...,  1.9077e+01,\n",
      "           5.2053e+01, -7.5331e+00],\n",
      "         [-1.0097e+01, -1.8794e+00,  1.9543e+01,  ..., -4.3446e+00,\n",
      "          -1.4370e+01,  1.9327e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 2.1558e+01, -6.0451e+00, -7.1011e+00,  ..., -2.9687e+01,\n",
      "           7.0832e+01, -4.1224e+01],\n",
      "         [ 2.3664e+01,  5.8981e+00, -4.9644e+01,  ..., -1.6606e+01,\n",
      "           3.4967e+01,  1.0328e+01],\n",
      "         [ 2.1996e+01, -1.2117e+01, -2.6355e+01,  ..., -4.7871e+01,\n",
      "           5.5427e+01, -5.1767e+01],\n",
      "         [ 3.6851e+01, -1.7574e+01, -3.1250e+01,  ...,  1.2616e+00,\n",
      "          -5.4304e+00,  2.8943e+01]],\n",
      "\n",
      "        [[-2.9717e+01, -2.8474e+01,  4.8225e+01,  ...,  6.1168e+00,\n",
      "           1.8940e+01, -3.8679e+01],\n",
      "         [ 6.9232e-01,  3.9357e-02, -1.1793e+01,  ..., -4.7441e+01,\n",
      "           1.1062e+01, -1.6813e+01],\n",
      "         [-2.5247e+01,  2.5582e+01, -1.5803e+01,  ...,  1.8897e+01,\n",
      "           5.2366e+01, -7.7686e+00],\n",
      "         [-1.0250e+01, -1.2869e+00,  1.8995e+01,  ..., -4.5637e+00,\n",
      "          -1.4299e+01,  1.9356e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 0.8558, -0.2381, -0.2800,  ..., -1.1751,  2.8086, -1.6323],\n",
      "         [ 1.0115,  0.2597, -2.0905,  ..., -0.6925,  1.4898,  0.4472],\n",
      "         [ 0.8958, -0.5082, -1.0942,  ..., -1.9797,  2.2718, -2.1401],\n",
      "         [ 1.5761, -0.7730, -1.3633,  ...,  0.0400, -0.2489,  1.2348]],\n",
      "\n",
      "        [[-1.2144, -1.1644,  1.9188,  ...,  0.2261,  0.7416, -1.5747],\n",
      "         [ 0.0395,  0.0122, -0.4829,  ..., -1.9745,  0.4734, -0.6930],\n",
      "         [-1.0765,  1.0369, -0.6838,  ...,  0.7590,  2.1506, -0.3497],\n",
      "         [-0.4220, -0.0380,  0.8311,  ..., -0.1784, -0.5955,  0.8465]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(layer,N)\n",
    "encoder_result = encoder(pe_result, mask)\n",
    "print(encoder_result)\n",
    "print(encoder_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
